{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from models.resnet import resnet50\n",
    "from my_dataset import MyDataset\n",
    "from my_lossfunc import JointLoss, MultilabelLoss, DiscriminativeLoss\n",
    "from my_transform import data_transforms\n",
    "from scipy.spatial.distance import pdist\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3\"\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('Device:', DEVICE)\n",
    "\n",
    "\n",
    "BASE = '/home/zengrui/datasets'\n",
    "DUKE_DIR_TRAIN = f'{BASE}/ReID_Duke/bounding_box_train'\n",
    "DUKE_DIR_TEST = f'{BASE}/ReID_Duke/bounding_box_test'\n",
    "DUKE_IMG_AMOUNT = 16522\n",
    "DUKE_ID_AMOUNT = 702\n",
    "MARKET_DIR_TRAIN = f'{BASE}/ReID_Market/bounding_box_train'\n",
    "MARKET_DIR_TEST = f'{BASE}/ReID_Market/bounding_box_test'\n",
    "MARKET_IMG_AMOUNT = 12936\n",
    "MARKET_ID_AMOUNT = 751\n",
    "ML_PATH = 'data/ml_Market.dat'\n",
    "PRETRAIN_PATH = 'data/pretrained_weight.pkl'\n",
    "PRETRAIN_OUT_PATH = 'data/pretrained_weight_{}.pkl'\n",
    "\n",
    "BATCH_SIZE = 96\n",
    "EPOCH = 30\n",
    "LR = 0.1\n",
    "\n",
    "BETA = 0.2\n",
    "LAMB1 = 2e-4\n",
    "LAMB2 = 50\n",
    "MARGIN = 1\n",
    "SCALA_CE = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_loader: ok.\n"
     ]
    }
   ],
   "source": [
    "# data loader\n",
    "data_loader = {\n",
    "    'source': DataLoader(\n",
    "        dataset=MyDataset(DUKE_DIR_TRAIN, \n",
    "                          transform=data_transforms('train')),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "    ),\n",
    "    'target': DataLoader(\n",
    "        dataset=MyDataset(MARKET_DIR_TRAIN,\n",
    "                          transform=data_transforms('train'),\n",
    "                          require_view=True),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "    ),\n",
    "}\n",
    "print('data_loader: ok.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self):\n",
    "        \n",
    "        # 网络\n",
    "        self.net = resnet50(pretrained=False, \n",
    "                            num_classes=DUKE_ID_AMOUNT)\n",
    "        self.net = nn.DataParallel(self.net).to(DEVICE)\n",
    "        if PRETRAIN_PATH is not None and os.path.exists(PRETRAIN_PATH):\n",
    "            self.net.load_state_dict(torch.load(PRETRAIN_PATH))\n",
    "            print('Pre-trained model loaded.')\n",
    "        else:\n",
    "            print('Pre-trained model not found. Train from scratch.')\n",
    "            \n",
    "        # 损失\n",
    "        self.mdl_loss = DiscriminativeLoss(0.001).to(DEVICE)\n",
    "        self.al_loss = nn.CrossEntropyLoss().to(DEVICE)\n",
    "        self.rj_loss = JointLoss(MARGIN).to(DEVICE)  # lack 1 param\n",
    "        self.cml_loss = MultilabelLoss(BATCH_SIZE).to(DEVICE)\n",
    "        \n",
    "        # 优化器\n",
    "        self.optimizer = torch.optim.SGD(\n",
    "            self.net.parameters(), lr=LR, momentum=0.9)\n",
    "        self.lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "            self.optimizer, milestones=[int(EPOCH / 8 * 5), int(EPOCH / 8 * 7)])\n",
    "        \n",
    "        # 存储器\n",
    "        self.ml_mem = torch.zeros(MARKET_IMG_AMOUNT, DUKE_ID_AMOUNT)\n",
    "        self.inited = self.ml_mem.sum(dim=1) != 0\n",
    "    \n",
    "    def train(self):\n",
    "        for epoch in range(EPOCH):\n",
    "            self.train_epoch(epoch)\n",
    "    \n",
    "    def train_epoch(self, epoch):\n",
    "        count = 0\n",
    "        running_loss = {'total': 0,\n",
    "                        'src': 0,\n",
    "                        'st': 0,\n",
    "                        'ml': 0,\n",
    "                        'tgt': 0,\n",
    "                       }\n",
    "        if not self.mdl_loss.initialized:  # ...\n",
    "            self.init_losses(data_loader['target'])\n",
    "        \n",
    "        with tqdm(total=len(data_loader['source'])) as pbar:\n",
    "            tgt_iter = iter(data_loader['target'])\n",
    "            for step, (ax, ay) in enumerate(data_loader['source']):\n",
    "                # a - source, b - target\n",
    "                ax = ax.to(DEVICE)\n",
    "                ay = ay.to(DEVICE)\n",
    "                try:\n",
    "                    b = next(tgt_iter)\n",
    "                except StopIteration:\n",
    "                    tgt_iter = iter(data_loader['target'])\n",
    "                    b = next(tgt_iter)\n",
    "                (bx, by, b_view, b_idx) = b\n",
    "                bx, by, b_view = bx.to(DEVICE), by.to(DEVICE), b_view.to(DEVICE)\n",
    "\n",
    "                a_f, a_sim, _ = self.net(ax)\n",
    "                b_f, b_sim, _ = self.net(bx)\n",
    "\n",
    "                loss_src = self.al_loss(a_sim * SCALA_CE, ay)  # 有监督 交叉熵\n",
    "                \n",
    "                agents = self.net.module.fc.weight.renorm(2, 0, 1e-5).mul(1e5)  # 归一化 shape=(702, 2048)\n",
    "                \n",
    "                loss_st = self.rj_loss(agents.detach(), a_f, a_sim.detach(), ay, \n",
    "                                       b_f, b_sim.detach())\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    ml = F.softmax(b_f.mm(agents.t_() * SCALA_CE), dim=1)  # t_(): 转置并inplace\n",
    "#                 loss_ml = self.cml_loss(torch.log(ml), b_view)\n",
    "\n",
    "                loss_ml = torch.Tensor([0]).to(DEVICE)\n",
    "    \n",
    "                if epoch < 1:  # 为什么第一轮不算 mdl_loss 呢\n",
    "                    loss_tgt = torch.Tensor([0]).to(DEVICE)\n",
    "                else:\n",
    "                    ml_cpu = ml.detach().cpu()\n",
    "                    is_inited_batch = self.inited[b_idx]\n",
    "                    inited_idx = b_idx[is_inited_batch]\n",
    "                    uninited_idx = b_idx[~is_inited_batch]\n",
    "                    self.ml_mem[uninited_idx] = ml_cpu[~is_inited_batch]  # 0标签满更新\n",
    "                    self.inited[uninited_idx] = True\n",
    "                    self.ml_mem[inited_idx] = 0.9 * self.ml_mem[inited_idx] \\\n",
    "                                            + 0.1 * ml_cpu[is_inited_batch]  # 非空标签小更新\n",
    "                    loss_tgt = self.mdl_loss(b_f, self.ml_mem[b_idx], by)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss_total = loss_tgt + LAMB1 * loss_ml + LAMB2 * (loss_src + BETA * loss_st)\n",
    "                loss_total.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                count += 1\n",
    "                loss_cpu = float(loss_total.data.cpu().numpy())\n",
    "                loss_src_cpu = float(loss_src.data.cpu().numpy())\n",
    "                loss_st_cpu = float(loss_st.data.cpu().numpy())\n",
    "                loss_ml_cpu = float(loss_ml.data.cpu().numpy())\n",
    "                loss_tgt_cpu = float(loss_tgt.data.cpu().numpy())\n",
    "                running_loss['total'] += loss_cpu\n",
    "                running_loss['src'] += loss_src_cpu\n",
    "                running_loss['st'] += loss_st_cpu\n",
    "                running_loss['ml'] += loss_ml_cpu\n",
    "                running_loss['tgt'] += loss_tgt_cpu\n",
    "                pbar.set_description('Loss: %.4f (%.4f + %.4f + %.4f + %.4f)' \n",
    "                                     % (loss_cpu, loss_src_cpu, loss_st_cpu, loss_ml_cpu, loss_tgt_cpu))\n",
    "                pbar.update()\n",
    "\n",
    "            self.lr_scheduler.step()\n",
    "            for k in running_loss.keys():\n",
    "                running_loss[k] /= count\n",
    "            print('Epoch: %d, Loss: %.4f (%.4f + %.4f + %.4f + %.4f)' \n",
    "                  % (epoch, running_loss['total'], running_loss['src'], \n",
    "                     running_loss['st'], running_loss['ml'], running_loss['tgt']))\n",
    "            \n",
    "    def init_losses(self, tgt_loader):\n",
    "        print('Initializing losses ....')\n",
    "        if os.path.isfile(ML_PATH):\n",
    "            (ml, view, pairwise_agreements) = torch.load(ML_PATH)\n",
    "            print('ml loaded.')\n",
    "        else:\n",
    "            print('ml not found, computing ....')\n",
    "            sim, _, views = extract_features(\n",
    "                data_loader['target'], self.net, index_feature=1, return_numpy=False)\n",
    "            ml = F.softmax(sim * SCALA_CE, dim=1)\n",
    "            ml_np = ml.cpu().numpy()\n",
    "            pairwise_agreements = 1 - pdist(ml_np, 'minkowski', p=1) / 2  # 相似比较特征\n",
    "            print('ml saving to %s...' % ML_PATH)\n",
    "            torch.save((ml, views, pairwise_agreements), ML_PATH)\n",
    "        log_ml = torch.log(ml)\n",
    "        # ...\n",
    "        self.mdl_loss.init_threshold(pairwise_agreements)\n",
    "        print('mdl_loss threshold inited.')\n",
    "        \n",
    "    def save_model(self, cover=False):\n",
    "        if cover:\n",
    "            torch.save(self.net.state_dict(), PRETRAIN_PATH)\n",
    "        else:\n",
    "            torch.save(self.net.state_dict(), PRETRAIN_OUT_PATH.format(time.time()))\n",
    "        print('Model weight saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained model not found. Train from scratch.\n",
      "Initializing losses ....\n",
      "ml loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mdl_loss threshold inited.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 393.0692 (7.5515 + 1.5497 + 0.0000 + 0.0000): 100%|██████████| 173/173 [06:00<00:00,  2.08s/it] \n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 572.2653 (11.2167 + 1.1430 + 0.0000 + 0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 353.1386 (6.7364 + 1.5626 + 0.0000 + 0.6931): 100%|██████████| 173/173 [06:42<00:00,  2.32s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 377.3244 (7.2226 + 1.5622 + 0.0000 + 0.5701)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 352.1070 (6.7072 + 1.6053 + 0.0000 + 0.6931): 100%|██████████| 173/173 [06:41<00:00,  2.32s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 365.2999 (6.9722 + 1.5994 + 0.0000 + 0.6931)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 353.6849 (6.7324 + 1.6371 + 0.0000 + 0.6931): 100%|██████████| 173/173 [06:44<00:00,  2.34s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 358.2038 (6.8254 + 1.6243 + 0.0000 + 0.6931)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 329.3775 (6.2483 + 1.6272 + 0.0000 + 0.6931): 100%|██████████| 173/173 [06:43<00:00,  2.34s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 351.8907 (6.6958 + 1.6407 + 0.0000 + 0.6931)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 333.5637 (6.3270 + 1.6519 + 0.0000 + 0.6931): 100%|██████████| 173/173 [06:43<00:00,  2.33s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 344.3794 (6.5429 + 1.6541 + 0.0000 + 0.6931)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 314.8884 (5.9568 + 1.6353 + 0.0000 + 0.6931): 100%|██████████| 173/173 [06:53<00:00,  2.39s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 335.6200 (6.3676 + 1.6549 + 0.0000 + 0.6931)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 344.4575 (6.5375 + 1.6888 + 0.0000 + 0.6928): 100%|██████████| 173/173 [06:48<00:00,  2.36s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss: 324.9527 (6.1550 + 1.6508 + 0.0000 + 0.6930)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 308.0649 (5.8183 + 1.6456 + 0.0000 + 0.6936): 100%|██████████| 173/173 [06:43<00:00,  2.33s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss: 310.0275 (5.8597 + 1.6348 + 0.0000 + 0.6925)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 333.0367 (6.3128 + 1.6703 + 0.0000 + 0.6921): 100%|██████████| 173/173 [06:42<00:00,  2.32s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss: 294.1223 (5.5463 + 1.6116 + 0.0000 + 0.6909)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 297.3013 (5.6075 + 1.6238 + 0.0000 + 0.6872): 100%|██████████| 173/173 [06:41<00:00,  2.32s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 275.1643 (5.1735 + 1.5803 + 0.0000 + 0.6846)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 365.8995 (6.9595 + 1.7269 + 0.0000 + 0.6552): 100%|██████████| 173/173 [06:43<00:00,  2.33s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Loss: 250.2498 (4.6837 + 1.5393 + 0.0000 + 0.6712)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 310.4696 (5.8718 + 1.6218 + 0.0000 + 0.6606): 100%|██████████| 173/173 [06:43<00:00,  2.33s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Loss: 223.2540 (4.1515 + 1.5020 + 0.0000 + 0.6565)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 273.7122 (5.1466 + 1.5664 + 0.0000 + 0.7189): 100%|██████████| 173/173 [06:44<00:00,  2.34s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Loss: 197.0531 (3.6360 + 1.4612 + 0.0000 + 0.6397)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 190.8086 (3.5112 + 1.4677 + 0.0000 + 0.5710): 100%|██████████| 173/173 [06:49<00:00,  2.37s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Loss: 172.5562 (3.1541 + 1.4224 + 0.0000 + 0.6278)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 254.7523 (4.7718 + 1.5464 + 0.0000 + 0.6979): 100%|██████████| 173/173 [06:50<00:00,  2.37s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Loss: 150.4413 (2.7217 + 1.3746 + 0.0000 + 0.6087)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 161.9988 (2.9558 + 1.3559 + 0.0000 + 0.6500): 100%|██████████| 173/173 [06:49<00:00,  2.37s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Loss: 131.0259 (2.3415 + 1.3333 + 0.0000 + 0.6189)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 116.5644 (2.0560 + 1.3253 + 0.0000 + 0.5130): 100%|██████████| 173/173 [06:48<00:00,  2.36s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Loss: 114.4985 (2.0195 + 1.2915 + 0.0000 + 0.6086)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 153.7216 (2.8047 + 1.2767 + 0.0000 + 0.7174): 100%|██████████| 173/173 [06:46<00:00,  2.35s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Loss: 90.0850 (1.5404 + 1.2454 + 0.0000 + 0.6095)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 122.4461 (2.1628 + 1.3635 + 0.0000 + 0.6701): 100%|██████████| 173/173 [06:45<00:00,  2.34s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Loss: 84.1443 (1.4233 + 1.2363 + 0.0000 + 0.6150)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 166.5662 (3.0424 + 1.3780 + 0.0000 + 0.6655): 100%|██████████| 173/173 [06:47<00:00,  2.36s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Loss: 82.2728 (1.3870 + 1.2321 + 0.0000 + 0.5995)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 200.6777 (3.7156 + 1.4307 + 0.0000 + 0.5913): 100%|██████████| 173/173 [06:43<00:00,  2.33s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Loss: 80.0774 (1.3437 + 1.2281 + 0.0000 + 0.6133)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 128.2402 (2.2912 + 1.3083 + 0.0000 + 0.5949): 100%|██████████| 173/173 [06:42<00:00,  2.33s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Loss: 77.7314 (1.2977 + 1.2234 + 0.0000 + 0.6123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 123.6079 (2.1921 + 1.3506 + 0.0000 + 0.4989): 100%|██████████| 173/173 [06:45<00:00,  2.34s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Loss: 76.8484 (1.2813 + 1.2180 + 0.0000 + 0.6042)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 193.6456 (3.5804 + 1.3972 + 0.0000 + 0.6520): 100%|██████████| 173/173 [06:46<00:00,  2.35s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Loss: 74.9093 (1.2428 + 1.2157 + 0.0000 + 0.6143)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 142.7090 (2.5681 + 1.3807 + 0.0000 + 0.4979): 100%|██████████| 173/173 [06:44<00:00,  2.34s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Loss: 73.0781 (1.2073 + 1.2100 + 0.0000 + 0.6123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 126.6697 (2.2507 + 1.3652 + 0.0000 + 0.4815): 100%|██████████| 173/173 [06:42<00:00,  2.33s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Loss: 70.8979 (1.1648 + 1.2051 + 0.0000 + 0.6088)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 160.2090 (2.9131 + 1.3996 + 0.0000 + 0.5577): 100%|██████████| 173/173 [06:48<00:00,  2.36s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Loss: 69.8352 (1.1436 + 1.2032 + 0.0000 + 0.6222)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 120.7345 (2.1270 + 1.3754 + 0.0000 + 0.6305): 100%|██████████| 173/173 [06:50<00:00,  2.37s/it]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Loss: 69.8719 (1.1446 + 1.2031 + 0.0000 + 0.6090)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 195.6564 (3.6103 + 1.4575 + 0.0000 + 0.5658): 100%|██████████| 173/173 [06:47<00:00,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Loss: 70.3622 (1.1542 + 1.2042 + 0.0000 + 0.6111)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()\n",
    "trainer.save_model(cover=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
